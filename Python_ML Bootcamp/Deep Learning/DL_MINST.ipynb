{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron including\n",
    "- input\n",
    "- processor\n",
    "- output\n",
    "- weights 介於 -1 ~ 1 之間\n",
    "- activation function 用來 predict output，有很多不同的function，根據你用的target不同有所不同\n",
    "- cost funcition 用來判斷誤差\n",
    "- backprobagation 調整誤差，<b>至於要調整的何時，調整到最靠進我是我們滿意</b>\n",
    "- 避免 input 都為0  => 加入bias(就是係他)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning\n",
    "- 很多個perceptron 所組成，有很多node(layer)所組成的 Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow\n",
    "- 想像是一個 Data Flow Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Tensorflow Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hello=tf.constant(\"Hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.framework.ops.Tensor"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(hello)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.framework.ops.Tensor"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=tf.constant(100)\n",
    "type(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Session:run tensor operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess=tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bytes"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# b is Unicode indication\n",
    "type(sess.run(hello))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.int32"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sess.run(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 operation\n",
    "- constant ： 就很像是 input\n",
    "    - sess.run(constant) 回傳numpy\n",
    "- 透過 tf.{function}，將這些input帶入function參數\n",
    "- session run the function (run activation)\n",
    "- recive input(constant) ，透過tf function 並用session run 這個function 產生output\n",
    "- session run 整個Data Flow 的過程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=tf.constant(2)\n",
    "y=tf.constant(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operations with constant\n",
      "Addition 5\n",
      "Subtraction -1\n",
      "Multiplation 6\n",
      "Division 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "#要做什麼\n",
    "with tf.Session() as sess:\n",
    "    print(\"Operations with constant\")\n",
    "    print(\"Addition\",sess.run(x+y))\n",
    "    print(\"Subtraction\",sess.run(x-y))\n",
    "    print(\"Multiplation\",sess.run(x*y))\n",
    "    print(\"Division\",sess.run(x/y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.int32)\n",
    "y= tf.placeholder(tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "add = tf.add(x,y)\n",
    "sub = tf.subtract(x,y)\n",
    "mul = tf.multiply(x,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operation with place holder\n",
      "additoon 50\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    print(\"Operation with place holder\")\n",
    "    print(\"additoon\",sess.run(add,feed_dict={x:20,y:30}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.array([[5.0,5.0]])\n",
    "b=np.array([2.0,2.0]).reshape(2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat1=tf.constant(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat2=tf.constant(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_multi=tf.matmul(mat1,mat2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result is : [[20.]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    print(\"result is :\",sess.run(matrix_multi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. MINST with Multi-Layer Perceptron \n",
    "- 手寫辨識資源庫，判斷數字的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist=input_data.read_data_sets(\"/tmp/data\",one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.contrib.learn.python.learn.datasets.base.Datasets"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(mnist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 一張圖有784個pixel ，每個pixel的數值代表顏色深淺\n",
    "- training data 有 55000張\n",
    "- testing data 有 10000張\n",
    "- input 是 一張裡面的全部特徵\n",
    "- output 就是 0-9 10 個代表label或是target有10個\n",
    "- #cost function 會用到 learning rate ，越低代表會更快優化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 784)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample=mnist.train.images[3].reshape(28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1c2d07c320>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c2cba84e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#imshow（可以帶入二為矩陣show圖，這個二維矩陣數字代表像素顏色的深淺）\n",
    "# imshow(數字大小代表像素的顏色深淺)\n",
    "plt.imshow(sample,cmap=\"Greys\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cost function 會用到 learning rate ，越低代表會更快優化\n",
    "learning_rate=0.001\n",
    "training_epoch=15\n",
    "batch_size=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes=10 #\n",
    "n_samples=mnist.train.num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input=784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden_1=256 #hidden layer 1 有 256個neuron\n",
    "n_hidden_2=256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1 透過 tensorflow 建立深度學習模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multilayerPerceptron(x,weights,biases):\n",
    "    \"\"\"\n",
    "    x:Placeholder\n",
    "    weights:Dict of weights\n",
    "    biases:dict of bias of value\n",
    "    \n",
    "    \"\"\"\n",
    "    # relu rectified linear uont 線性整流函數\n",
    "    \n",
    "    # First Hidden Layer with RELU Activation\n",
    "    # X * W + B\n",
    "    layer_1=tf.add(tf.matmul(x,weights['h1']),biases['b1'])\n",
    "    \n",
    "    # Activate Function:relu (激勵函數：主要是引入非線性)\n",
    "    ## nn 是 neural network\n",
    "    # Func(X * W + B) = RELU => f(x) = max(0,x)\n",
    "    layer_1=tf.nn.relu(layer_1)\n",
    "    \n",
    "    #Second Hidden Layer\n",
    "    layer_2=tf.add(tf.matmul(layer_1,weights[\"h2\"]),biases[\"b2\"])\n",
    "    layer_2=tf.nn.relu(layer_2)\n",
    "    \n",
    "    #Last output Layer \n",
    "    out_layer = tf.matmul(layer_2,weights[\"out\"])+biases[\"out\"]\n",
    "    \n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.2 設定參數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights={\n",
    "    # 權重個數做交叉相乘得出有多少個權重（多少條edge）\n",
    "    \"h1\":tf.Variable(tf.random_normal([n_input,n_hidden_1])),\n",
    "    \"h2\":tf.Variable(tf.random_normal([n_hidden_1,n_hidden_2])),\n",
    "    \"out\":tf.Variable(tf.random_normal([n_hidden_2,n_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "biases={\n",
    "    \"b1\":tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    \"b2\":tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    \"out\":tf.Variable(tf.random_normal([n_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 因為後面要矩陣所以這裡shape是（none,feature數）\n",
    "x=tf.placeholder(\"float\",[None,n_input]) # x 餵像素\n",
    "y=tf.placeholder(\"float\",[None,n_classes]) # y 判別為哪個數值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=multilayerPerceptron(x,weights,biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce_mean 先降維再平均\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels = y, logits = pred))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Training Model Run the Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 從training data 任選幾筆資料\n",
    "t=mnist.train.next_batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t[0] 代表 feature，t[1] 代表 label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y=t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1c47992eb8>"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c478810f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x.reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/jiajiaping/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py:118: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    }
   ],
   "source": [
    "init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'numpy.ndarray'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-198-8b019e5b6979>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m# 我們只需要cost funtion就好\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch_y\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mavg_cost\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtotal_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Epoch:{} cost:{:.4f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mavg_cost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'numpy.ndarray'"
     ]
    }
   ],
   "source": [
    "# 15 loops\n",
    "for epoch in range(training_epoch):\n",
    "    #Cost\n",
    "    avg_cost=0.0\n",
    "    total_batch=int(n_samples/batch_size)\n",
    "    \n",
    "    for i in range(total_batch):\n",
    "        #next_batch 不會每次都取一樣的\n",
    "        batch_x,batch_y=mnist.train.next_batch(batch_size)\n",
    "        \n",
    "        # 我們只需要cost funtion就好\n",
    "        _, c = sess.run([optimizer,cost], feed_dict={x:batch_x, y:batch_y})\n",
    "        avg_cost += c/total_batch\n",
    "    print(\"Epoch:{} cost:{:.4f}\".format(epoch+1,avg_cost))\n",
    "print(\"Model has completed {} Epochs of training\".format(training_epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "0.9175\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    " \n",
    "import tensorflow as tf\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    " \n",
    "W = tf.Variable(tf.zeros([784, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    " \n",
    "y = tf.nn.softmax(tf.matmul(x, W) + b)\n",
    " \n",
    "y_ = tf.placeholder(tf.float32, [None, 10])\n",
    " \n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))\n",
    " \n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
    " \n",
    "sess = tf.InteractiveSession()\n",
    " \n",
    "tf.global_variables_initializer().run()\n",
    " \n",
    "for _ in range(1000):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "    sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n",
    " \n",
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    " \n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    " \n",
    "print(sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 建立深度學習的另一種方式 \n",
    "- tensorflow.contrib.learn SKFlow\n",
    "- 因為 Tensor flow 還算蠻複雜的，所以Sklearn 建立一個API接口到Tensorflow 叫做skflow\n",
    "- from tenserflow.contlib.learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris=load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names'])"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=iris[\"data\"]\n",
    "y=iris[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(x,y,test_size=0.4,random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.contrib.learn as learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sepal length (cm)',\n",
       " 'sepal width (cm)',\n",
       " 'petal length (cm)',\n",
       " 'petal width (cm)']"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris[\"feature_names\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/np/5vqp70vx075czzm7wv6l_8n40000gn/T/tmprupv6892\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x1c251b8e10>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/var/folders/np/5vqp70vx075czzm7wv6l_8n40000gn/T/tmprupv6892'}\n"
     ]
    }
   ],
   "source": [
    "#設定\n",
    "feature_columns = [tf.contrib.layers.real_valued_column(\"\", dimension=4)]\n",
    "classifier=learn.DNNClassifier(hidden_units=[10,20,10],feature_columns=feature_columns,n_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /var/folders/np/5vqp70vx075czzm7wv6l_8n40000gn/T/tmprupv6892/model.ckpt.\n",
      "INFO:tensorflow:loss = 1.0640442, step = 1\n",
      "INFO:tensorflow:global_step/sec: 1194\n",
      "INFO:tensorflow:loss = 0.19479215, step = 101 (0.084 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 200 into /var/folders/np/5vqp70vx075czzm7wv6l_8n40000gn/T/tmprupv6892/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.13069391.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DNNClassifier(params={'head': <tensorflow.contrib.learn.python.learn.estimators.head._MultiClassHead object at 0x1c251b8b00>, 'hidden_units': [10, 20, 10], 'feature_columns': (_RealValuedColumn(column_name='', dimension=4, default_value=None, dtype=tf.float32, normalizer=None),), 'optimizer': None, 'activation_fn': <function relu at 0x10edf7598>, 'dropout': None, 'gradient_clip_norm': None, 'embedding_lr_multipliers': None, 'input_layer_min_slice_size': None})"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train,y_train,steps=200,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /var/folders/np/5vqp70vx075czzm7wv6l_8n40000gn/T/tmprupv6892/model.ckpt-200\n"
     ]
    }
   ],
   "source": [
    "iris_predictions = classifier.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object DNNClassifier.predict_classes.<locals>.<genexpr> at 0x1c21f6e1a8>"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    " \n",
    "import tensorflow as tf\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    " \n",
    "W = tf.Variable(tf.zeros([784, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    " \n",
    "y = tf.nn.softmax(tf.matmul(x, W) + b)\n",
    " \n",
    "y_ = tf.placeholder(tf.float32, [None, 10])\n",
    " \n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))\n",
    " \n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
    " \n",
    "sess = tf.InteractiveSession()\n",
    " \n",
    "tf.global_variables_initializer().run()\n",
    " \n",
    "for _ in range(1000):\n",
    "  batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "  sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n",
    " \n",
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    " \n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    " \n",
    "print(sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x1c251b9320>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': './output'}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ./output/model.ckpt-2000\n",
      "INFO:tensorflow:Saving checkpoints for 2001 into ./output/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.06180684, step = 2001\n",
      "INFO:tensorflow:global_step/sec: 1001.18\n",
      "INFO:tensorflow:loss = 0.05985032, step = 2101 (0.101 sec)\n",
      "INFO:tensorflow:global_step/sec: 1271.56\n",
      "INFO:tensorflow:loss = 0.059243828, step = 2201 (0.079 sec)\n",
      "INFO:tensorflow:global_step/sec: 1218.41\n",
      "INFO:tensorflow:loss = 0.058725934, step = 2301 (0.082 sec)\n",
      "INFO:tensorflow:global_step/sec: 1289.92\n",
      "INFO:tensorflow:loss = 0.058273282, step = 2401 (0.078 sec)\n",
      "INFO:tensorflow:global_step/sec: 1272.98\n",
      "INFO:tensorflow:loss = 0.057869297, step = 2501 (0.078 sec)\n",
      "INFO:tensorflow:global_step/sec: 1152.87\n",
      "INFO:tensorflow:loss = 0.05750238, step = 2601 (0.088 sec)\n",
      "INFO:tensorflow:global_step/sec: 1103.15\n",
      "INFO:tensorflow:loss = 0.057164006, step = 2701 (0.089 sec)\n",
      "INFO:tensorflow:global_step/sec: 1201.7\n",
      "INFO:tensorflow:loss = 0.05684816, step = 2801 (0.084 sec)\n",
      "INFO:tensorflow:global_step/sec: 1239.4\n",
      "INFO:tensorflow:loss = 0.05655043, step = 2901 (0.080 sec)\n",
      "INFO:tensorflow:global_step/sec: 1227.9\n",
      "INFO:tensorflow:loss = 0.05626753, step = 3001 (0.081 sec)\n",
      "INFO:tensorflow:global_step/sec: 1115.15\n",
      "INFO:tensorflow:loss = 0.055997085, step = 3101 (0.090 sec)\n",
      "INFO:tensorflow:global_step/sec: 1217.27\n",
      "INFO:tensorflow:loss = 0.055737346, step = 3201 (0.082 sec)\n",
      "INFO:tensorflow:global_step/sec: 1270.31\n",
      "INFO:tensorflow:loss = 0.055487182, step = 3301 (0.079 sec)\n",
      "INFO:tensorflow:global_step/sec: 1171.26\n",
      "INFO:tensorflow:loss = 0.055245467, step = 3401 (0.085 sec)\n",
      "INFO:tensorflow:global_step/sec: 1255.73\n",
      "INFO:tensorflow:loss = 0.055011485, step = 3501 (0.080 sec)\n",
      "INFO:tensorflow:global_step/sec: 1063.54\n",
      "INFO:tensorflow:loss = 0.054784775, step = 3601 (0.094 sec)\n",
      "INFO:tensorflow:global_step/sec: 1044.94\n",
      "INFO:tensorflow:loss = 0.054564938, step = 3701 (0.096 sec)\n",
      "INFO:tensorflow:global_step/sec: 1155.58\n",
      "INFO:tensorflow:loss = 0.054351494, step = 3801 (0.087 sec)\n",
      "INFO:tensorflow:global_step/sec: 1158.83\n",
      "INFO:tensorflow:loss = 0.054144233, step = 3901 (0.087 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4000 into ./output/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.05394494.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-23-15:44:43\n",
      "INFO:tensorflow:Restoring parameters from ./output/model.ckpt-4000\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-23-15:44:43\n",
      "INFO:tensorflow:Saving dict for global step 4000: accuracy = 1.0, global_step = 4000, loss = 0.01646211\n",
      "Accuracy: 1.000000\n",
      "INFO:tensorflow:Restoring parameters from ./output/model.ckpt-4000\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        17\n",
      "          1       1.00      1.00      1.00        15\n",
      "          2       1.00      1.00      1.00        13\n",
      "\n",
      "avg / total       1.00      1.00      1.00        45\n",
      "\n",
      "\n",
      "\n",
      "[[17  0  0]\n",
      " [ 0 15  0]\n",
      " [ 0  0 13]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    " \n",
    "# Data sets\n",
    "iris = load_iris()\n",
    "X =np.float32(iris['data']) \n",
    "y = iris['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3)\n",
    " \n",
    "# Specify that all features have real-value data\n",
    "feature_columns = [tf.contrib.layers.real_valued_column(\"\", dimension=4)]\n",
    " \n",
    "# Build 3 layer DNN with 10, 20, 10 units respectively.\n",
    "classifier = tf.contrib.learn.DNNClassifier(feature_columns=feature_columns,\n",
    "                                            hidden_units=[10, 20, 10],\n",
    "                                            n_classes=3,\n",
    "                                            model_dir=\"./output\")\n",
    " \n",
    "# Fit model.\n",
    "classifier.fit(X_train, y_train, steps=2000)\n",
    " \n",
    "# Evaluate accuracy.\n",
    "accuracy_score = classifier.evaluate(X_test, y_test)[\"accuracy\"]\n",
    "print('Accuracy: {0:f}'.format(accuracy_score))\n",
    " \n",
    "#Evaluate with classification report and confusion matrix\n",
    "iris_predictions = list(classifier.predict(X_test))\n",
    "print(classification_report(y_test,  iris_predictions))\n",
    "print('\\n')\n",
    "print(confusion_matrix(y_test,  iris_predictions))\n",
    "print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
